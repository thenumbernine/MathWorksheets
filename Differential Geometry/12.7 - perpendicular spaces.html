<!doctype html>
<html>
	<head>
		<meta charset='utf-8'>
		<title>perpendicular spaces</title>
		<script type="text/javascript" src='../tryToFindMathJax.js'></script>
	</head>
	<body>
<a href='index.html'>Back</a><br>
<br>

Let $\mathcal{M}$ be our manifold of dimension n<br>
Lets separate it into a hypersurface/submanifold $\Sigma$ of dimension m.<br>
Let $e_i, i \in \{1, ..., m\}$ be our basis elements of the submanifold.<br>
Let $e_i, i \in \{m+1, ..., n\}$ be our basis elements of the orthogonal space.<br>
Lets use a coordinate basis so $e_i = \partial_i$ and $[e_i, e_j] = 0$.<br>
<br>

Let $\eta(x) = \delta_{ij} \cdot \sigma_i = diag(\sigma_1 ... \sigma_n)$ be the diagonalization of the metric of the manifold at some coordinate $x = \{ x^1 ... x^n \}$, for $\sigma_i \in \pm1$.<br>
So $\eta = \eta_{ij} e^i \otimes e^j = \sigma_i \cdot \delta_{ij} e^i \otimes e^j$<br>

$\eta = i \downarrow \overset{j \rightarrow}{
\left[ \begin{matrix} 
	\sigma_1 	& 			& 0 		\\
				& \ddots 	& 			\\
	0 			& 			& \sigma_n
\end{matrix} \right]
}$<br>
<br>

Let $\eta^\perp = diag(\sigma_1 ... \sigma_m, \underset{\times (n-m)}{\underbrace{0 ... 0}})$ be the diagonalization of the metric of the submanifold at some point $x^a$.<br>
So $\eta^\perp = (\eta^\perp)_{ij} e^i \otimes e^j$ and $(\eta^\perp)_{ij} = 0$ for i or j $\in \{ m+1 ... n\}$, or otherwise $= \eta_{ij}$.<br>

$\eta^\perp = i \downarrow \overset{j \rightarrow}{
\left[ \begin{array}{ccc|cc}
	\sigma_1 	& 			& 0 		& 0 &			& 0 	\\
				& \ddots 	& 			& 	& \ddots 	&		\\
	0 			& 			& \sigma_m	& 0 & 	 	 	& 0 	\\
	\hline                                         
	0 			& 			& 0 		& 0 & 	 	 	& 0 	\\
				& \ddots	& 			& 	& \ddots 	&		\\
	0 			& 			& 0 		& 0 & 			& 0
\end{array} \right]
}$<br>
<br>

Let $\eta^\top = diag(\underset{\times m}{\underbrace{0 ... 0}}, \sigma_{m+1} ... \sigma_n)$ be the diagonalization of the metric of the space perpendicular to the submanifold at point $x^a$.<br>
So $\eta^\top = (\eta^\top)_{ij} e^i \otimes e^j$ and $(\eta^\top)_{ij} = 0$ for i or j $\in \{1 ... m\}$ or otherwise $= \eta_{ij}$.<br>

$\eta^\top = i \downarrow \overset{j \rightarrow}{
\left[ \begin{array}{ccc|cc}
	0 			& 			& 0 		& 0 &			& 0 	\\
				& \ddots 	& 			& 	& \ddots 	&		\\
	0 			& 			& 0			& 0 & 	 	 	& 0 	\\
	\hline                                         
	0 			& 			& 0 		& \sigma_{m+1} & 	 	 	& 0 	\\
				& \ddots	& 			& 	& \ddots 	&		\\
	0 			& 			& 0 		& 0 & 			& \sigma_n
\end{array} \right]
}$<br>
<br>

So $\eta = \eta^\perp + \eta^\top$<br>
<br>



Let $\Sigma$ be the basis of the submanifold.<br>
$\Sigma = (-1)^{m(n-m)} \eta_{m+1...n}$<br>
$= (-1)^{m(n-m)} \epsilon_{m+1...n \ 1...m} e^1 \wedge ... \wedge e^m$<br>
$= \epsilon_{1 ... m \ m+1 ... n} e^1 \wedge ... \wedge e^m$<br>
$= \sqrt{|g|} e^1 \wedge ... \wedge e^m$<br>
$= \sqrt{|g|} m! e^{[1} \otimes ... \otimes e^{m]}$<br>
$= \sqrt{|g|} \delta^{1 ... m}_{i_1 ... i_m} e^{i_1} \otimes ... \otimes e^{i_m}$<br> 
$= \frac{1}{m!} \epsilon_{i_1 ... i_m \ m+1 ... n} e^{i_1} \wedge ... \wedge e^{i_m}$<br>
$= \epsilon_{i_1 ... i_m \ m+1 ... n} e^{[i_1} \otimes ... \otimes e^{i_m]}$<br>
$= \epsilon_{i_1 ... i_m \ m+1 ... n} e^{i_1} \otimes ... \otimes e^{i_m}$<br>
So that in component form:<br>
$\Sigma = \Sigma_{i_1 ... i_m} e^{i_1} \otimes ... \otimes e^{i_m}$<br>
for $\Sigma_{i_1 ... i_m} = \sqrt{|g|} \delta^{1 ... m}_{i_1 ... i_m}$<br>
$\Sigma_{i_1 ... i_m} = \sqrt{|g|} m! \delta^1_{[i_1} \cdot ... \cdot \delta^m_{i_m]}$<br>
$\Sigma_{i_1 ... i_m} = \epsilon_{i_1 ... i_m \ m+1 ... n}$<br>
<br>

So $e_j \lrcorner \Sigma$<br>
$= \epsilon_{i_1 ... i_m \ m+1 ... n} (e^{i_1} \otimes ... \otimes e^{i_m}) (e_j)$<br>
$= \epsilon_{i_1 ... i_m \ m+1 ... n} e^{i_1} (e_j) e^{i_2} \otimes ... \otimes e^{i_m}$<br>
$= \epsilon_{i_1 ... i_m \ m+1 ... n} \delta^{i_1}_j e^{i_2} \otimes ... \otimes e^{i_m}$<br>
$= \epsilon_{j \ i_2 ... i_m \ m+1 ... n} e^{i_2} \otimes ... \otimes e^{i_m}$<br>
So $\Sigma(e_j) = 0$ for $j \in \{ m+1 ... n \}$, 
and $\Sigma(e_j) = \pm \sqrt{|g|}$ for $j \in  \{ 1 ... m \}$.<br>
<br>

Let $N = \star \Sigma$ be the basis of the perpendicular space.<br>
$N = \sqrt{|g|} *(e^1 \wedge ... \wedge e^m)$<br>
$= \sqrt{|g|} e^{m+1} \wedge ... \wedge e^n$<br>
$= \eta_{1 ... m}$<br>
$= \epsilon_{1 ... m \ m+1 ... n} e^{m+1} \wedge ... \wedge e^n$<br>
$= \sqrt{|g|} (n-m)! e^{[m+1} \otimes ... \otimes e^{n]}$<br>
$= \sqrt{|g|} \delta^{m+1 ... n}_{i_{m+1} ... i_n} e^{i_{m+1}} \otimes ... \otimes e^{i_n}$<br>
$= \frac{1}{(n-m)!} \epsilon_{1 ... m \ i_{m+1} ... i_n} e^{i_{m+1}} \wedge ... \wedge e^{i_n}$<br>
$= \epsilon_{1 ... m \ i_{m+1} ... i_n} e^{[i_{m+1}} \otimes ... \otimes e^{i_n]}$<br>
$= \epsilon_{1 ... m \ i_{m+1} ... i_n} e^{i_{m+1}} \otimes ... \otimes e^{i_n}$<br>
So that in compoent form:<br>
$N = N_{i_{m+1} ... i_n} e^{i_{m+1}} \otimes ... \otimes e^{i_n}$<br>
for $N_{i_{m+1} ... i_n} = \sqrt{|g|} \delta^{m+1 ... n}_{i_{m+1} ... i_n}$<br>
for $N_{i_{m+1} ... i_n} = \sqrt{|g|} (n-m)! \delta^{m+1}_{i_{m+1}} \cdot ... \cdot \delta^n_{i_n}$<br>
$N_{i_{m+1} ... i_n} = \epsilon_{1 ... m \ i_{m+1} ... i_n}$<br>
<br>

So $e_j \lrcorner N$<br>
$= \epsilon_{1 ... m \ i_{m+1} ... i_n} (e^{i_{m+1}} \otimes ... \otimes e^{i_n}) (e_j)$<br>
$= \epsilon_{1 ... m \ i_{m+1} ... i_n} e^{i_{m+2}} \otimes ... \otimes e^{i_n} \delta^{i_{m+1}}_j$<br>
$= \epsilon_{1 ... m \ j \ i_{m+2} ... i_n} e^{i_{m+2}} \otimes ... \otimes e^{i_n}$<br>
$= 0$ if $j \in \{ 1 ... m \}$ since our permutation tensor $\epsilon_I$ will get repeated-index.<br>
$= \pm \sqrt{|g|}$ if $j \in \{ m+1 ... n \}$ since we don't have repeated roots.<Br>
<br>

Let $n^i$ be the the i'th normal form.<br>
Define the i'th normal $n^i$ as the inverse of the non-coordinate transform to diagonalize the metric but only for the $i \in \{m+1 ... n\}$ indexes:<br>
$n^i = (n^i)_u e^u = {e^i}_u e^u$,<br>

Notice that, for diagonalization:<br>
$g_{uv}$<br>
$= e_u \cdot e_v$<br>
$= {e^i}_u {e^j}_v \eta_{ij}$<br>
$= {e^i}_u {e^j}_v (\eta^\perp_{ij} + \eta^\top_{ij})$<br>
$= 
	{e^i}_u {e^j}_v \eta^\perp_{ij}
	+ \frac{1}{\alpha_i} (n^i)_u \frac{1}{\alpha_j} (n^j)_v \eta^\top_{ij} 
$<br>
$= \underset{{i,j \in [m+1,n]}}{\Sigma} \frac{1}{\alpha_i} (n^i)_u \frac{1}{\alpha_j} (n^j)_v \eta^\top_{ij} 
	+ \underset{{i,j \in [1,m]}}{\Sigma} {e^i}_u {e^j}_v \eta^\perp_{ij}
$<br>
So you still need influence from the submanifold basis.<br>

<br>
In contrast:<br>
$(\eta^\top)^{ij}$<br>
$= {e^i}_u {e^j}_v g^{uv}$<br>
$= \frac{1}{\alpha_i} \frac{1}{\alpha_j} (n^i)_u (n^j)_v g^{uv}$<br>
TODO is this true?:<br>
for linear diagonalization of the metric ${e^i}_u$ such that ${e^i}_u {e^j}_v (\eta^\top)_{ij} = g_{uv}$<br>
so $n \eta^\top n = {n^i}_u (\eta^\top)_{ij} {n^j}_v e^u \otimes e^v = g_{uv} e^u \otimes e^v$<br>
<br>

There are multiple ways to define an inverse diagonalization ${e^i}_u = (n^i)_u$.<br>
Choose the specific diagonalization: 
$	n^i 
	= -(\alpha_i) \nabla (x^i) 
	= -(\alpha_i) e^u \nabla_u (x^i) 
	= -(\alpha_i) e^u \delta_u^i 
	= -(\alpha_i) e^i
$<br>
Normalize it so $\sigma_i = (\alpha_i)^2 n^i \cdot n^i = (\alpha_i)^2 g^{ii}$<br>
Notice that $\alpha_i$ is a scalar, not tensoral, and the i index isn't paired with a basis element.<br>
<br>

The vector form of normal $n^i$ is: 
$
	n^i
	= (n^i)_u e^u
	= (n^i)^u e_u
	= g^{uv} (n^i)_v e_u 
	= -g^{uv} (\alpha_i) \delta^i_v e_u 
	= -g^{ui} (\alpha_i) e_u
$<br>
So $(n^i)^u = -g^{ui} (\alpha_i)$<br>
Let $(\beta_i)^u = g^{ui} (\alpha_i)$ be the i'th shift vector.<br>
<br>

TODO the i'th $\beta_i$ will have to be raised/lowered by by the submatrix of $\eta - \overset{i-1}{\underset{j=m+1}{\Sigma}} n_j \eta n_j$<br>
<br>

I think this definition of $n^i = (n^i)_u e^u = {e^i}_u e^u$ should work with the definition of $N = \star \Sigma$ as well.<br>
Then $\gamma \ne g + N \otimes N$ can be used as well..<br>
<br>

Let $
	\gamma 
	= \gamma_{uv} e^u \otimes e^v 
	= g - n \eta^\top n
	= g - (\eta^\top)_{ij} n^i \otimes n^j
	= (g_{uv} - (\eta^\top)_{ij} {n^i}_u {n^j}_v)(e^u \otimes e^v)
$ be the projection operator<br>
<br>

So for $k \in \{1 ... m\}$:<br>
$\gamma(e_k)$<br>
$= (g_{uv} - (\eta^\top)_{ij} {n^i}_u {n^j}_v)(e^u \otimes e^v) (e_k)$<br>
$= (g_{uv} - (\eta^\top)_{ij} {e^i}_u {e^j}_v) \delta^u_k e^v$<br>
$= (g_{uv} - (\eta^\top)_{ij} (\alpha_i) (\alpha_j) \delta^i_u \delta^j_v) \delta^u_k e^v$<br>
$= (g_{kv} - (\eta^\top)_{kv} (\alpha_k) (\alpha_v)) e^v$<br>
Since $k \in \{1 ... m\}, (\eta^\top)_{kv} = 0$<br>
$= g_{kv} e^v$<br>
$= e_k$<br>
<br>

And for $k \in \{m+1 ... n \}$:<br>
$\gamma(e_k)$<br>
$= (g - n \eta^\top n) (e_k)$<br>
$= (g_{kv} - (\eta^\top)_{kv} (\alpha_k) (\alpha_v)) e^v$<br>
Since $k \in \{1 ... m\}, (\eta^\top)_{kv} = \eta_{kv} = \delta_{kv} \sigma_k$<br>
$= (g_{kv} - \delta_{kv} \sigma_k (\alpha_k) (\alpha_v)) e^v$<br>
TODO prove this is equal ... seems like I'll have to use raised $(n^i)^u = -g^{iu} (\alpha_i)$ somehow.<br>
$= 0$<br>
<br>

$\gamma_{ab} = a \downarrow \overset{b \rightarrow}{
\left[ \begin{array}{ccc|c|c}
	\gamma_{11}		& \cdots	& \gamma_{im}		& (\beta_{m+1})_1									& \cdots	& (\beta_n)_1 						\\
	\vdots			& \ddots 	& \vdots			& \vdots											& \ddots 	& \vdots							\\
	\gamma_{m1}		& \cdots	& \gamma_{mm}		& (\beta_{m+1})_m									& \cdots	& (\beta_n)_m 						\\
	\hline
	(\beta_{m+1})_1 & \cdots	& (\beta_{m+1})_m	& (\beta_{m+1})_{m+1} = -\frac{1}{(\alpha_{m+1})^2}	& \cdots	& (\beta_{m+1})_n = (\beta_n)_{m+1}	\\
	\hline	
					& \ddots	& 					& \vdots											& \ddots 	& \vdots							\\
	\hline
	(\beta_n)_1		& \cdots 	& (\beta_n)_m 		& (\beta_{m+1})_n = (\beta_n)_{m+1} 				& 			& (\beta_n)_n = -\frac{1}{(\alpha_n)^2}
\end{array} \right]
}$<br>
<br>



<br>
<a href='index.html'>Back</a><br>
	</body>
</html>
